Chain-of-thought (CoT) prompting
Selecting transcript lines in this section will navigate to timestamp in the video
- If I gave you a logic puzzle like Miken has five apples and gives chase two of them, how many apples does Miken and have left? You would go through a chain of thoughts to figure out how to solve the puzzle. Now, when we work with AI systems, we can use few shot prompting to provide examples of chains of thought and then have the system match those patterns in its own so-called Reasoning to solve logic puzzles. This is called chain of thought prompting. Let me show you an example of this. So first I'm going to show you what happens if I don't provide any examples. So here we have a logic puzzle. Tracy used a piece of wire four feet long to support tomato plants in her garden. The wire was cut into pieces six inches long. How many pieces did she obtain? So if I run this in ChatGPT, ChatGPT will try to figure this out and it will go through some sort of logic process and it'll probably get the answer right, but not all the time. The thing is we can show ChatGPT how to solve this kind of puzzle if we wanted to solve it in a specific way. And if we have something more advanced we want it to do, we can also show it how to do that through examples. That's what chain of thought prompting is. In the exercise files, I have three different types of chain of thought prompting. First I have few shots, then I have zero plus few shot, and then finally I have a zero shot example. So we'll start with a few shot example here. In this example I have a series of questions and answers. So each question is a logic puzzle. And each answer walks through a process of how to solve this puzzle. And you'll notice there's a very specific pattern here. It starts by breaking down the puzzle and then it always says the answer is and then whatever the answer is. And then at the very bottom we have a question. Tracy used a piece of wire four feet long. So this is the same question as before. All right. Let's run this and see how the output is different. So in the previous example, you remember it provided this huge explanation and it did a bunch of math here because we provided examples through our few shot learning and a thought process through chain of thoughts. It's following the chain of thoughts pattern instead. And we get a better result. But the result still isn't as good as we probably want it. So we can go on to zero plus few shot. So what the only difference here is that in addition to having the answer, I start every single answer by let's think step by step. So I'm forcing the system to think step by step. The only other difference in this prompt is in addition to having the question here, Tracy used a piece of wire four feet long, we also start the answer by saying, let's think step by step because that matches with all the other answers we have here. And when I run this, you'll notice because I created a pattern and I'm telling the system to follow the pattern, it's following the pattern much closer. So here we have a much shorter answer and the answer also says at the end. The answer is eight because that matches the overall pattern. This is very useful and this kind of chain of thought reasoning is used a lot in AI systems, both in ChatGPT and also in built AI systems using APIs. And you will customize your questions and answer patterns to get the system to match the type of solution patterns you want. This isn't restricted to just math questions, you can do it to other things too. So if you have a process and you want it to match your process exactly, you provide examples of how to solve it and it'll try to match this process. But in the process of researching this, some researchers came across a really interesting phenomenon within these AI systems. Take a look at the third example here, the one that's called zero shot chain of thoughts. Notice how there is no examples, it's just a question. And then let's think step by step. Let's see what happens if I put this into the system. So just a question. Let's think step by step first, comma, let's see what it does. Now the system will create its own process and then walk through the entire process step by step and spell out what is happening. And this strategy telling the system to go step by step has turned out to be one of the most powerful prompt engineering techniques out there. Who would've thought? Well, it actually makes a lot of sense because these AI systems are trained on the content on the internet, and a lot of content on the internet is training material. And a lot of that training material is from schools. And if you go read school books about how to do things, specifically math, you'll often see the term, let's think step-by-step or go through this step-by-step. So what we're telling the system is go find in your training material examples of how people are using the term let's go step by step on the responses that come after. And that's the pattern that matches. So if you're working with any of these AI systems, you're trying to get it to do a task and it's not producing the right answer or not doing the task the right way, try to just tell it let's do this step by step and see what it does. More often than not, it'll produce a better output.