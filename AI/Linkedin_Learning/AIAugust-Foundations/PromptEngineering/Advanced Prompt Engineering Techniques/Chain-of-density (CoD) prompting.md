- And for my final trick, or in this case, advanced prompt engineering technique, I'm going to show you something that the first time I saw it, I couldn't quite believe this was possible, but based on everything we've seen so far in this course, you can see that this particular technique, called chain of density takes everything we've talked about so far and stitches it all together into one giant prompt that does something that quite frankly, is amazing. This technique is called chain of density prompting, and it's used to summarize huge piles of text into a very, very solid summary. The way it works is by taking all the text and finding all the main points within the text and then making a summary and then testing itself to say, did you actually cover all the main points? If not, what are the main points that were missed? Go back and make another summary that includes those main points and then it does this again and again and again and again until all the main points are actually covered in the summary. So effectively, it's the same thing as doing a bunch of separate summaries, where each time you go in and tell it, Hey, you missed this important point, except you get the AI to do it all in one prompt. Let's take a look. Let's take that article about the capability approach I used earlier in the course. So I'll scroll down here and find the first section. Now, I'm only going to take the first section because we don't want to run out of token context here. Basically, if you paste too much content into an AI system, it can't process all the content, so it just clips off whatever's at the top. So you need to make sure that the length of what you're trying to summarize isn't too big. So in this case, because I have a giant article, I'll chunk it into pieces and do it piece by piece. But in this course, I'll only do the first piece because we're not actually looking at the capability approach here, we're looking at how the AI system works. Anyway, first I'll put the content in, I'll say article, colon on and just paste in the entire article. Then I'll go to my GitHub repo and grab this giant prompt here. So I'll copy it out first, and then we can take a look at what it says. So I'll paste that in here and run this prompt. And while the system is working, we can take a look at what's going on here. You will generate increasingly concise, entity dense summaries of the above article. Repeat the following two steps five times. Step one, identify one to three informative entities, and that means like important pieces. Then step two, write a new denser summary of identical length, which covers every entity in detail from the previous summary plus the missing entity. And then it lists out what an entity is and how to identify it. And then it has a bunch of guidelines, including how long the summary should be, and that every word counts and a bunch of other stuff. You can read through this on your own and see what's actually happening. And then it says, remember, use the exact same number of words for each summary. Now, it's not going to use the exact same number of words. This is just a way of enforcing that the length should be roughly the same, because if you've ever tried to get an AI system to count, you'll quickly discover it can't, no matter how much you try. Finally, it says answer in JSON. The JSON should be a list, length five of dictionaries whose key words are missing entities, and denser summary. Now that we've given Chat GPT some time to think, let's see what it did. So here we have the output, so missing entities, and then we have a denser summary. So here you're getting all the five summaries 'cause you remember this is done in five cycles. So if I scroll up a bit so I can grab the scroller, you'll see we have five different summaries and they're quite long and they're spelled out like this so that we can really see what happened. So this is the first summary, and then the system went into the summary and said, what's missing here? Well, what's missing is the Tanner lectures and utilitarian measures. So then the second summary will contain these two pieces. Then we look at it and say, what's missing this time? Real freedoms, functionings, Nussbaum's partial theory of something, and then we go on and on and on until we get down to the fifth one. Now, in the prompts, you can go in and change the number of cycles, like two steps. five times. You can make like, 10 times or whatever you want, and you'll get increasingly denser summaries. But what you'll discover if you go down here is the fourth or fifth summary is usually the best one, because at a certain point when you're doing this process, eventually it'll start crunching the things together so much that the summaries almost become unreadable because there is no person here, there is no entity reading the content, it's just following the instructions. And because we're asking for density, it can actually make it too dense, but it's worth trying just to see. But what you're seeing here is currently the ultimate example of how advanced these systems can be if you give them proper instructions. We are now telling it to summarize the thing five times and review its own work and output all of them so we can see what it did and review its work and then pick the best output. This also shows you that when we get this far into advanced prompt engineering, we're really into the programming area, and the way that this content is output as JSON fits perfectly into an application. So if you were to use the open AI API with this prompt, you would get JSON out, then you could then continue parsing in an application. So for example, you could build a summarization tool for academic work. Now that you've seen all these advanced prompt engineering techniques, it's time for you to go out in the real world and use them. (speaks in foreign language) and I'll see you in the next course.


- And for my final trick, or in this case, advanced prompt engineering technique, I'm going to show you something that the first time I saw it, I couldn't quite believe this was possible, but based on everything we've seen so far in this course, you can see that this particular technique, called chain of density takes everything we've talked about so far and stitches it all together into one giant prompt that does something that quite frankly, is amazing. This technique is called chain of density prompting, and it's used to summarize huge piles of text into a very, very solid summary. The way it works is by taking all the text and finding all the main points within the text and then making a summary and then testing itself to say, did you actually cover all the main points? If not, what are the main points that were missed? Go back and make another summary that includes those main points and then it does this again and again and again and again until all the main points are actually covered in the summary. So effectively, it's the same thing as doing a bunch of separate summaries, where each time you go in and tell it, Hey, you missed this important point, except you get the AI to do it all in one prompt. Let's take a look. Let's take that article about the capability approach I used earlier in the course. So I'll scroll down here and find the first section. Now, I'm only going to take the first section because we don't want to run out of token context here. Basically, if you paste too much content into an AI system, it can't process all the content, so it just clips off whatever's at the top. So you need to make sure that the length of what you're trying to summarize isn't too big. So in this case, because I have a giant article, I'll chunk it into pieces and do it piece by piece. But in this course, I'll only do the first piece because we're not actually looking at the capability approach here, we're looking at how the AI system works. Anyway, first I'll put the content in, I'll say article, colon on and just paste in the entire article. Then I'll go to my GitHub repo and grab this giant prompt here. So I'll copy it out first, and then we can take a look at what it says. So I'll paste that in here and run this prompt. And while the system is working, we can take a look at what's going on here. You will generate increasingly concise, entity dense summaries of the above article. Repeat the following two steps five times. Step one, identify one to three informative entities, and that means like important pieces. Then step two, write a new denser summary of identical length, which covers every entity in detail from the previous summary plus the missing entity. And then it lists out what an entity is and how to identify it. And then it has a bunch of guidelines, including how long the summary should be, and that every word counts and a bunch of other stuff. You can read through this on your own and see what's actually happening. And then it says, remember, use the exact same number of words for each summary. Now, it's not going to use the exact same number of words. This is just a way of enforcing that the length should be roughly the same, because if you've ever tried to get an AI system to count, you'll quickly discover it can't, no matter how much you try. Finally, it says answer in JSON. The JSON should be a list, length five of dictionaries whose key words are missing entities, and denser summary. Now that we've given Chat GPT some time to think, let's see what it did. So here we have the output, so missing entities, and then we have a denser summary. So here you're getting all the five summaries 'cause you remember this is done in five cycles. So if I scroll up a bit so I can grab the scroller, you'll see we have five different summaries and they're quite long and they're spelled out like this so that we can really see what happened. So this is the first summary, and then the system went into the summary and said, what's missing here? Well, what's missing is the Tanner lectures and utilitarian measures. So then the second summary will contain these two pieces. Then we look at it and say, what's missing this time? Real freedoms, functionings, Nussbaum's partial theory of something, and then we go on and on and on until we get down to the fifth one. Now, in the prompts, you can go in and change the number of cycles, like two steps. five times. You can make like, 10 times or whatever you want, and you'll get increasingly denser summaries. But what you'll discover if you go down here is the fourth or fifth summary is usually the best one, because at a certain point when you're doing this process, eventually it'll start crunching the things together so much that the summaries almost become unreadable because there is no person here, there is no entity reading the content, it's just following the instructions. And because we're asking for density, it can actually make it too dense, but it's worth trying just to see. But what you're seeing here is currently the ultimate example of how advanced these systems can be if you give them proper instructions. We are now telling it to summarize the thing five times and review its own work and output all of them so we can see what it did and review its work and then pick the best output. This also shows you that when we get this far into advanced prompt engineering, we're really into the programming area, and the way that this content is output as JSON fits perfectly into an application. So if you were to use the open AI API with this prompt, you would get JSON out, then you could then continue parsing in an application. So for example, you could build a summarization tool for academic work. Now that you've seen all these advanced prompt engineering techniques, it's time for you to go out in the real world and use them. (speaks in foreign language) and I'll see you in the next course.