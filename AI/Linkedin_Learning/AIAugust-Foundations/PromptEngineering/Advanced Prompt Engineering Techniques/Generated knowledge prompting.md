Generated knowledge prompting
Selecting transcript lines in this section will navigate to timestamp in the video
- By now, we know that providing reference material for context vastly improves the performance of an AI system. And that if we use few shot prompting combined with chain of thought examples, we can show the system how to perform specific tasks. Which brings up an important question, how do you create all these examples? Because in many cases you don't necessarily have a database of examples of how you want the system to do things. The cool thing is you can actually get the AI system to build out the examples for you. This is called generated knowledge prompting. Let me show you an example. Here, I have a novel question. The pinky toe has no functional purpose, and if I run this in GPT-4, we'll get a response that explains something about this issue. Now, this is just a trivial example. It could be anything, but let's say I want a specific format for my answer, not this huge thing you see here. To achieve that, I can turn to few shot prompting, but I need a bunch of examples. And ideally I want examples that have reference information that relates to my questions. The good news is I can get the AI system to generate these examples for me, using generated knowledge prompting, and this is what that looks like. So I start off with this prompt here. What we have here is a series of inputs with a statement and then knowledge components, which are facts about that statement. And what I want the system to do now is generate a new statement based on my question or my statement. Now, when I run this, because I'm providing a bunch of examples of the structure, the system will repeat that structure and output a similar piece of knowledge for me. Now that I have this knowledge, I can then start asking questions based on this knowledge, as the baseline and I'll get better results than if I was just asking the question outright. So now I can take this question and say, "Why does the pinky toe have no functional purpose?" And because I have that knowledge piece at the top, it'll now use that knowledge piece to answer my question. Bear in mind, this is a really trivial example, and this is one of those cases where I encourage you to go check out the links file and go look at the original academic paper and the example that's provided on GitHub to see how it really works. Because this type of prompting is more effective if you use it inside a built-out application through an API, so that you first generate the knowledge and then send questions based on that knowledge later. But if you are trying to do something where you want a specific kind of output or you want to generate a bunch of examples for something, this proves that you can use the AI to generate those examples. All you need is a couple of examples of the format you want for your knowledge or your pattern or whatever it is, 



Here are the key takeaways from the "Generated knowledge prompting" video:

Generated knowledge prompting: This technique involves using the AI system to create examples for tasks when you don't have a pre-existing database of examples.
Improved performance: By generating structured examples, the AI can provide better responses to specific questions.
Application: This method is particularly effective when integrated into applications through an API, allowing for the generation of knowledge and subsequent question-answering based on that knowledge.

These points highlight how you can leverage AI to create useful examples and improve the accuracy of responses.